#!/bin/bash
# source script.cfg


columnName=$1

IFS='/' read -a myarray <<< "$2"

echo "input bucket name: ${myarray[2]}"
echo "input folder name: ${myarray[3]}"

IFS='/' read -a myarray2 <<< "$3"

echo "output bucket name: ${myarray2[2]}"
echo "output folder name: ${myarray2[3]}"
bucketName=${myarray2[2]}
inputBucket=${myarray[2]}

# argument reference
#columnName=$1
input=${myarray[3]}
output=${myarray2[3]}

echo "the bucket will not be created, make sure it exists"
echo $bucketName
exit
# uncomment
# aws s3 mb s3://$bucketName

# maven cleaning
mvn clean compile assembly:single

# moving jar to current location
cp target/DistributedEC2Sorting-0.0.1-SNAPSHOT-jar-with-dependencies.jar .

# the file that contains the public DNS addresses of the linux boxes that we just started
FILE=publicDnsFile.txt

# moving files to server and cleaning previous run files

while read line;do
        echo $line" copying"
        ssh -i MyKeyPair.pem -o stricthostkeychecking=no ubuntu@$line 'rm -rf ~/Project/s3LocalInput/' < /dev/null
        ssh -i MyKeyPair.pem -o stricthostkeychecking=no ubuntu@$line 'rm ~/Project/*.hprof' < /dev/null
        scp -i MyKeyPair.pem -o stricthostkeychecking=no DistributedEC2Sorting-0.0.1-SNAPSHOT-jar-with-dependencies.jar ubuntu@$line:~/Project < /dev/null
done < $FILE

# This loop will ssh into the machines represented by each line generated by the starter script
# The ssh command uses stdin, and hence it directly exits the loop
# to avoid that, we attach the output to nothing, so that it can continue the loop for as long as there are
# lines in the file that we are reading from
# IMPORTANT: We will be runnning the java program on each instance, so we dont wait for one program to
# complete and exit
comds="cd ~/Project; java -XX:+HeapDumpOnOutOfMemoryError -Xmx5120m -Xms256m  -cp ~/Project/DistributedEC2Sorting-0.0.1-SNAPSHOT-jar-with-dependencies.jar server.Server $i $inputBucket $bucketName  $input $output > log.txt 2>&1"
comdsserver="rm -rf ~/Project/sampleSortPartTemp/; rm ~/Project/sampleSortMyParts/*;cd ~/Project; java -XX:+HeapDumpOnOutOfMemoryError -Xmx5120m -Xms256m  -cp ~/Project/DistributedEC2Sorting-0.0.1-SNAPSHOT-jar-with-dependencies.jar server.Server 0 $inputBucket $bucketName  $input $output > log.txt 2>&1"
#comdsclient="cd ~/Project; java -cp DistributedEC2Sorting-0.0.1-SNAPSHOT-jar-with-dependencies.jar server.Server 0 $inputBucket > ~/Project/log.txt &"
i=0
server="not decided"
while read line;do
        echo "$line"
        echo $i
        if [ $i -eq 0 ]; then
        	server=$line
                `ssh -i MyKeyPair.pem ubuntu@$line -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no "${comdsserver}"` < /dev/null &
        else
        	echo "slave instance"
                `ssh -i MyKeyPair.pem ubuntu@$line -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no "rm -rf ~/Project/sampleSortPartTemp/; rm ~/Project/sampleSortMyParts/*;cd ~/Project; java -XX:+HeapDumpOnOutOfMemoryError -Xmx5120m -Xms256m  -cp ~/Project/DistributedEC2Sorting-0.0.1-SNAPSHOT-jar-with-dependencies.jar server.Server $i $inputBucket $bucketName  $input $output > log.txt 2>&1"` < /dev/null &
        fi
        i=$((i+1))
done < $FILE
echo "master instance was "$server
sleep 10s
java -cp DistributedEC2Sorting-0.0.1-SNAPSHOT-jar-with-dependencies.jar client.Client $inputBucket $bucketName $input $output
# since we started the programs simultaneously, we will wait for the two of them to complete after this step
wait
echo "reached the end of sort script"
echo "exiting sort script"
# uncomment if you wish to download the output to your computer
echo "Download the output from the s3 bucket to your computer"
#echo aws s3 sync s3://$bucketName/DistributedEC2Sort output/
exit
